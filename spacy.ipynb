{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lit le fichier des gares et filtrent sur les gares qui accueillent des voyageurs\n",
    "liste_gare = pd.read_csv(\"./liste-des-gares.csv\", sep=';')\n",
    "liste_gare = liste_gare.loc[liste_gare[\"VOYAGEURS\"] == \"O\"]\n",
    "\n",
    "#Lit le jeu de tests\n",
    "liste_phrase_test = pd.read_csv(\"./liste-de-phrases.csv\", sep=\";\")\n",
    "liste_phrase_test[\"étapes\"] = liste_phrase_test[\"étapes\"].fillna(\"\") #remplace les NaN par une string vide, ça permet d'éviter des erreurs\n",
    "\n",
    "#Applique des filtres sur la liste des gares pour une analyse approfondie plus tard par l'ia\n",
    "gares = list(liste_gare[\"COMMUNE\"])\n",
    "gares = [x.lower() for x in gares]\n",
    "gares_without_starting = [x[2:] for x in gares if x[0:2] == \"l'\"]\n",
    "gares_without_dash = [x.replace(\"-\", \" \") for x in gares if \"-\" in x]\n",
    "gares = [x[2:] if x[0:2] == \"l'\" else x for x in gares]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hermitage',\n",
       " 'isle-jourdain',\n",
       " \"hospitalet-pres-l'andorre\",\n",
       " 'etang-la-ville',\n",
       " 'aigle',\n",
       " 'isle-sur-le-doubs',\n",
       " 'escarene',\n",
       " 'isle-sur-la-sorgue',\n",
       " 'etang-la-ville',\n",
       " \"isle-d'abeau\",\n",
       " 'argentiere-la-bessee',\n",
       " 'etang-la-ville',\n",
       " 'hopital-du-grosbois']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gares_without_starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste des prépositions et verbe nécessaire à l'analyse sémantique\n",
    "preposition_depart = [\"de\", \"depuis\", \"à\", \"sur\", \"dans\", \"vers\"]\n",
    "preposition_destination = [\"à\", \"pour\", \"sur\", \"dans\", \"jusque\", \"jusqu'à\", \"vers\", \"de\"]\n",
    "preposition_in_both = [\"de\", \"à\", \"sur\", \"dans\", \"vers\"]\n",
    "preposition_etape = [\"par\", \"via\", \"puis\", \"et\"]\n",
    "preposition = set(preposition_depart + preposition_destination + preposition_etape)\n",
    "\n",
    "verbe_action = [\"aller\", \"partir\", \"rendre\", \"rejoindre\", \"retourner\"]\n",
    "verbe_potentiel_action = [\"vouloir\", \"souhaiter\", \"essayer\", \"devoir\", \"pouvoir\", \"aimer\"]\n",
    "verbe_etapes = [\"passer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste de la ponctuation\n",
    "ponctuation_list = [\".\", \",\", \";\", \":\", \"!\", \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_treatment(text):\n",
    "    #Prétraitement des données pour une meilleur analyse\n",
    "    text = text.lower()\n",
    "\n",
    "    #On retire toute ponctuation parce qu'elles ne sont pas utiles\n",
    "    for ponctu in ponctuation_list:\n",
    "        text = text.replace(ponctu, \"\")\n",
    "    \n",
    "    #On recherche les noms de gares qui ont un nom qui peut poser des problèmes \n",
    "    for city in gares_without_dash:\n",
    "        if city in text:\n",
    "           text = text.replace(city, city.replace(\" \", \"-\"))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['à', 'ADP'],\n",
       "  ['PARIS', 'LOC'],\n",
       "  ['aimer', 'POT_ACTION'],\n",
       "  ['STRASBOURG', 'LOC'],\n",
       "  ['pouvoir', 'POT_ACTION']],\n",
       " [{'ADP': 'à', 'LOC': 'PARIS'}, {'ADP': '', 'LOC': 'STRASBOURG'}]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Pendant mon séjour à Paris, j'aimerais visiter Strasbourg. Peux tu me trouver un itinéraire ?\"\n",
    "def get_main_data(text):\n",
    "    \"\"\"\n",
    "        Retourne une analyse sémantique de la phrase passé en paramètre, elle retourne un array contenant:\n",
    "            - un array avec les labels de chaque mot de la forme [mot, label]\n",
    "            - la première ville trouvée avec la préposition qui l'accompagne si trouvé: [ville] ou [préposition, ville]\n",
    "            - la deuxième ville trouvée avec la préposition qui l'accompagne si trouvé: [ville] ou [préposition, ville]\n",
    "    \"\"\"\n",
    "    #Initialisation des variables\n",
    "    doc = nlp(text)\n",
    "    position = []\n",
    "    locs = []\n",
    "\n",
    "    #Analyse sémantique de la phrase\n",
    "    for w in doc:\n",
    "        w_text = w.text\n",
    "        if w.pos_ == \"ADP\" and w_text in preposition:\n",
    "            position.append([w_text, w.pos_])\n",
    "        if w_text in gares:\n",
    "            #Pour une gare, on cherche à récupérer la préposition qui vient avant s'il y en a une et ensuite on ajoute nos résultats à locs et position\n",
    "            tmp_loc = {\n",
    "                \"ADP\": \"\",\n",
    "                \"LOC\": \"\"\n",
    "            }\n",
    "            if position and position[-1][1] == \"ADP\":\n",
    "                tmp_loc[\"ADP\"] = position[-1][0]\n",
    "            tmp_loc[\"LOC\"] = w_text.upper()\n",
    "            locs.append(tmp_loc)\n",
    "            position.append([w_text.upper(), \"LOC\"])\n",
    "        if w.pos_ == \"VERB\" and w.lemma_ in verbe_action:\n",
    "            position.append([w.lemma_, \"ACTION\"])\n",
    "        if w.pos_ == \"VERB\" and w.lemma_ in verbe_potentiel_action:\n",
    "            position.append([w.lemma_, \"POT_ACTION\"])\n",
    "    return [position, locs]\n",
    "#print([(w.text, w.label_) for w in doc.ents])\n",
    "text = data_treatment(text)\n",
    "get_main_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_departure(loc, loc_2):\n",
    "    \"\"\"\n",
    "        vérifie si une ville est la ville de départ dans une phrase\n",
    "    \"\"\"\n",
    "    if loc[\"ADP\"] != \"\":\n",
    "        if loc[\"ADP\"] not in preposition_in_both:\n",
    "            if loc[\"ADP\"] in preposition_depart:\n",
    "                return True\n",
    "    elif loc[\"ADP\"] == \"\" and loc_2[\"ADP\"] == \"\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_name(loc_1, loc_2):\n",
    "    \"\"\"\n",
    "        Récupère le nom de la ville dans un array qui peut prendre la forme [Préposition, ville] ou [ville] \n",
    "    \"\"\"\n",
    "    return [loc_1[\"LOC\"], loc_2[\"LOC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_de_a(loc_1, loc_2):\n",
    "    \"\"\"\n",
    "        Vérifie si on se retrouve dans le cas d'une phrase avec 2 villes, et les prépositions \"de, à\" devant le nom des villes\n",
    "    \"\"\"\n",
    "    prep1 = loc_1[\"ADP\"]\n",
    "    prep2 = loc_2[\"ADP\"]\n",
    "    if prep1 in [\"de\", \"à\"] and prep2 in [\"de\", \"à\"]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PARIS', 'STRASBOURG', '']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_position(text):\n",
    "    \"\"\"\n",
    "        Retourne les villes trouvées dans le sens départ, destination ou une erreur si ce n'est pas possible\n",
    "    \"\"\"\n",
    "    text = data_treatment(text)\n",
    "    #On fait une première analyse sémantique pour récupérer des infos essentielles, voir fonction get_main_data() \n",
    "    [data, locs] = get_main_data(text)\n",
    "\n",
    "    #Actuellement, si on a pas 2 villes on retourne une erreur\n",
    "    if len(locs) <= 1:\n",
    "        return [\"Il manque des villes ou des villes n'ont pas été détecté. Il se peut aussi que la ville n'a pas été détecté parce qu'il n'y a pas de gare\"]\n",
    "    \n",
    "    depart, destination, etapes = \"\", \"\", []\n",
    "\n",
    "    #On commence par chercher les étapes en premier\n",
    "    for city in locs:\n",
    "        if city[\"ADP\"] in preposition_etape:\n",
    "            etapes.append(city[\"LOC\"])\n",
    "            locs.remove(city)\n",
    "    \n",
    "    if len(locs) == 2:\n",
    "        loc_1, loc_2 = locs\n",
    "    \n",
    "        #if, elif permettent de chercher des cas simples sémantiquement et gagner du temps de travail, pour les cas plus complexes voir le else\n",
    "        if is_departure(loc_1, loc_2):\n",
    "            depart = loc_1[\"LOC\"]\n",
    "            destination = loc_2[\"LOC\"]\n",
    "        elif is_departure(loc_2, loc_1):\n",
    "            depart = loc_2[\"LOC\"]\n",
    "            destination = loc_1[\"LOC\"]\n",
    "        elif is_de_a(loc_1, loc_2):\n",
    "            if loc_1[\"ADP\"] == \"de\":\n",
    "                depart = loc_1[\"LOC\"]\n",
    "                destination = loc_2[\"LOC\"]\n",
    "            else:\n",
    "                depart = loc_2[\"LOC\"]\n",
    "                destination = loc_1[\"LOC\"]\n",
    "        else:\n",
    "            pot_action = False\n",
    "            action = False\n",
    "            \n",
    "            #Analyse est divisé en 2 partie, la première est ce que j'appelle \n",
    "            # le potentiel d'action ou pot_action, qui a pour but d'analyser l'intention d'une phrase à l'aide de sa sémantique\n",
    "            # par exemple: je souhaite aller à Paris, grâce au verbe souhaiter, on sait que la personne \"souhaite\"(à l'intention de) se rendre à Paris\n",
    "            for [w, label] in data:\n",
    "                if label == \"POT_ACTION\":\n",
    "                    pot_action = True\n",
    "                    pass\n",
    "                \n",
    "                if pot_action:\n",
    "                    if label == \"LOC\":\n",
    "                        destination = w\n",
    "                        cities = get_city_name(loc_1, loc_2)\n",
    "                        for city in cities:\n",
    "                            if city != w:\n",
    "                                depart = city\n",
    "                        break\n",
    "            \n",
    "            #si il n'y a pas d'intention dans la phrase, on passe à la deuxième partie d'analyse, \n",
    "            # l'action, on va chercher à savoir si sémantiquement une action est déclaré,\n",
    "            #  par exemple: je vais à paris. grâce au verbe aller on sait qu'une action va se produire ou se déroule\n",
    "            if not destination:\n",
    "                for [w, label] in data:\n",
    "                    if label == \"ACTION\":\n",
    "                        action = True\n",
    "                        pass\n",
    "                    if action:\n",
    "                        if label == \"LOC\":\n",
    "                            destination = w\n",
    "                            cities = get_city_name(loc_1, loc_2)\n",
    "                            for city in cities:\n",
    "                                if city != w:\n",
    "                                    depart = city\n",
    "                            break\n",
    "    #Retourne le résultat de l'analyse en faisant une transformation sur les données par la même occasion pour les villes spéciales\n",
    "    return [\"L'\" + x if x.lower() in gares_without_starting else x for x in [depart, destination, \",\".join(etapes)]]\n",
    "get_position(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je souhaite visiter un musée de Paris, je pars de strasbourg\n",
      "Je vais visiter un musée de paris, je pars de strasbourg\n",
      "Je suis à strasbourg et je retourne à paris\n",
      "Je veux aller à Paris en partant de Strasbourg et en passant par Dijon et Bordeaux\n",
      "Strasbourg j'irai, de Paris je partirai\n",
      "Strasbourg j'irai, de Paris je partirai, par Lyon je passerai\n",
      "En passant par Lyon et bordeaux, j'aimerais partir à strasbourg depuis Paris\n",
      "En passant par Lyon puis bordeaux, j'aimerais partir à strasbourg depuis Paris\n",
      "Nombre passé:  28\n",
      "Nombre non passé:  8\n",
      "Nombre total:  36\n"
     ]
    }
   ],
   "source": [
    "#Process de tests pour calculer les résultats de l'IA\n",
    "nb_passed, nb_no_passed = 0, 0\n",
    "\n",
    "for i, data in liste_phrase_test.iterrows():\n",
    "    sentence = data[\"phrase\"]\n",
    "    destination = data[\"destination\"]\n",
    "    depart = data[\"départ\"]\n",
    "    etapes = data[\"étapes\"]\n",
    "    \n",
    "    if [depart.upper(), destination.upper(), etapes.upper()] == get_position(sentence):\n",
    "        nb_passed += 1\n",
    "    else:\n",
    "        print(sentence)\n",
    "        [data, locs] = get_main_data(sentence)\n",
    "        #print(locs)\n",
    "        nb_no_passed += 1\n",
    "\n",
    "print(\"Nombre passé: \", nb_passed)\n",
    "print(\"Nombre non passé: \", nb_no_passed)\n",
    "print(\"Nombre total: \", nb_passed + nb_no_passed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 'ADP'), ('passant', 'VERB'), ('par', 'ADP'), ('lyon', 'PROPN'), ('et', 'CCONJ'), ('bordeaux', 'ADJ'), (\"j'\", 'PRON'), ('aimerais', 'VERB'), ('partir', 'VERB'), ('à', 'ADP'), ('strasbourg', 'PROPN'), ('depuis', 'ADP'), ('paris', 'PROPN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['par', 'ADP'],\n",
       "  ['LYON', 'LOC'],\n",
       "  ['BORDEAUX', 'LOC'],\n",
       "  ['aimer', 'POT_ACTION'],\n",
       "  ['partir', 'ACTION'],\n",
       "  ['à', 'ADP'],\n",
       "  ['STRASBOURG', 'LOC'],\n",
       "  ['depuis', 'ADP'],\n",
       "  ['PARIS', 'LOC']],\n",
       " [[['par', 'ADP'], ['LYON', 'LOC']],\n",
       "  [['BORDEAUX', 'LOC']],\n",
       "  [['à', 'ADP'], ['STRASBOURG', 'LOC']],\n",
       "  [['depuis', 'ADP'], ['PARIS', 'LOC']]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Permet de développer l'analyse d'une phrase qui ne serait pas passer\n",
    "text_test = \"En passant par Lyon et bordeaux, j'aimerais partir à strasbourg depuis Paris\"\n",
    "text_test = data_treatment(text_test)\n",
    "doc = nlp(text_test)\n",
    "print([(w.text, w.pos_) for w in doc])\n",
    "\n",
    "get_main_data(text_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
